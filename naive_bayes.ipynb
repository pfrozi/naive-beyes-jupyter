{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(Utilizando Laplace smoothing 10.00000)\nCarregando dataset balanceado\n\tDataset possui 3675 spams de um total de 5175 emails (percentual de spams: 71.00%)\nFazendo predicoes no conjunto de teste...\nAcuracia: 100.0000%\t(100 of 100)\n"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import pickle\n",
    "import sys\n",
    "from random import randint\n",
    "\n",
    "DATA_DIR = 'enron'\n",
    "target_names = ['ham', 'spam']\n",
    "\n",
    "def get_data(DATA_DIR, arq):\n",
    "    #subfolders = ['enron%d' % i for i in range(1,2)]\n",
    "    subfolders = ['enron%d' % arq]\n",
    "\n",
    "    data = []\n",
    "    target = []\n",
    "    for subfolder in subfolders:\n",
    "        # spam\n",
    "        spam_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'spam'))\n",
    "        for spam_file in spam_files:\n",
    "            #original:\n",
    "            #with open(os.path.join(DATA_DIR, subfolder, 'spam', spam_file), encoding=\"latin-1\") as f:\n",
    "            with open(os.path.join(DATA_DIR, subfolder, 'spam', spam_file)) as f:\n",
    "                data.append(f.read())\n",
    "                target.append(1)\n",
    "\n",
    "        # ham\n",
    "        ham_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'ham'))\n",
    "        for ham_file in ham_files:\n",
    "            #original:\n",
    "            #with open(os.path.join(DATA_DIR, subfolder, 'ham', ham_file), encoding=\"latin-1\") as f:\n",
    "            with open(os.path.join(DATA_DIR, subfolder, 'ham', ham_file)) as f:    \n",
    "                data.append(f.read())\n",
    "                target.append(0)\n",
    "\n",
    "    return data, target\n",
    "\n",
    "class SpamDetector(object):\n",
    "    \"\"\"Implementation of Naive Bayes for binary classification\"\"\"\n",
    "    def clean(self, s):\n",
    "        return s.translate(None, string.punctuation)\n",
    "        #original:\n",
    "        #translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        #return s.translate(translator)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        text = self.clean(text).lower()\n",
    "        return re.split(\"\\W+\", text)\n",
    "\n",
    "    def get_word_counts(self, words):\n",
    "        word_counts = {}\n",
    "        for word in words:\n",
    "            word_counts[word] = word_counts.get(word, 0.0) + 1.0\n",
    "        return word_counts\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Fit our classifier\n",
    "        Arguments:\n",
    "            X {list} -- list of document contents\n",
    "            y {list} -- correct labels\n",
    "        \"\"\"\n",
    "        self.log_class_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.vocab = set()\n",
    "\n",
    "        n = 1.0*len(X)\n",
    "        self.log_class_priors['spam'] = math.log(sum(1 for label in Y if label == 1) / n)\n",
    "        self.log_class_priors['ham'] = math.log(sum(1 for label in Y if label == 0) / n)\n",
    "        self.word_counts['spam'] = {}\n",
    "        self.word_counts['ham'] = {}\n",
    "\n",
    "        for x, y in zip(X, Y):\n",
    "            c = 'spam' if y == 1 else 'ham'\n",
    "            counts = self.get_word_counts(self.tokenize(x))\n",
    "            for word, count in counts.items():\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab.add(word)\n",
    "                if word not in self.word_counts[c]:\n",
    "                    self.word_counts[c][word] = 0.0\n",
    "\n",
    "                self.word_counts[c][word] += count\n",
    "\n",
    "    def predict(self, X, use_laplace_smoothing, laplace_smoothing_term, print_unknown_words_spam, print_unknown_words_ham):\n",
    "        result = []\n",
    "        laplace_sum_1 = sum(self.word_counts['spam'].values()) + laplace_smoothing_term*len(self.vocab)\n",
    "        laplace_sum_2 = sum(self.word_counts['ham'].values()) + laplace_smoothing_term*len(self.vocab)\n",
    "\n",
    "        for x in X:\n",
    "            counts = self.get_word_counts(self.tokenize(x))\n",
    "            spam_score = 0\n",
    "            ham_score = 0\n",
    "\n",
    "            spam_zero_frequency_word = False # does the email has a zero-frequency word in the spam class? Then P(spam)=0 if not using LS\n",
    "            ham_zero_frequency_word = False # does the email has a zero-frequency word in the ham class? Then P(ham)=0 if not using LS\n",
    "            \n",
    "            for word, _ in counts.items():\n",
    "                if word not in self.vocab: continue\n",
    "                                \n",
    "                if use_laplace_smoothing:\n",
    "                    log_w_given_spam = math.log( (self.word_counts['spam'].get(word, 0.0) + laplace_smoothing_term) / (laplace_sum_1) )\n",
    "                    log_w_given_ham = math.log( (self.word_counts['ham'].get(word, 0.0) + laplace_smoothing_term) / (laplace_sum_2) )\n",
    "                else:\n",
    "                    if self.word_counts['spam'].get(word, 0.0)==0:\n",
    "                        if print_unknown_words_spam:\n",
    "                            print \"\\tPalavra --%s--- tem contagem zero na classe SPAM\" % word\n",
    "                        spam_zero_frequency_word = True\n",
    "                        log_w_given_spam = 0.0\n",
    "                    else:\n",
    "                        log_w_given_spam = math.log( (self.word_counts['spam'].get(word, 0.0) + laplace_smoothing_term) / (laplace_sum_1) )\n",
    "                        \n",
    "                    if self.word_counts['ham'].get(word, 0.0)==0:\n",
    "                        if print_unknown_words_ham:\n",
    "                            print \"\\tPalavra --%s--- tem contagem zero na classe NAO-SPAM\" % word\n",
    "                        ham_zero_frequency_word = True\n",
    "                        log_w_given_ham = 0.0\n",
    "                    else:\n",
    "                        log_w_given_ham = math.log( (self.word_counts['ham'].get(word, 0.0) + laplace_smoothing_term) / (laplace_sum_2) )    \n",
    "\n",
    "                spam_score += log_w_given_spam\n",
    "                ham_score += log_w_given_ham\n",
    "\n",
    "            spam_score += self.log_class_priors['spam']\n",
    "            ham_score += self.log_class_priors['ham']\n",
    "            \n",
    "            if spam_zero_frequency_word:\n",
    "                spam_score = 0.0 # if no laplace smoothing was used and there was a zero-frequency word in the email, P(spam)=0\n",
    "            if ham_zero_frequency_word:\n",
    "                ham_score = 0.0  # if no laplace smoothing was used and there was a zero-frequency word in the email, P(ham)=0\n",
    "                \n",
    "            if spam_score == ham_score:\n",
    "                result.append(randint(0,1))\n",
    "            else:\n",
    "                if spam_score > ham_score:\n",
    "                    result.append(1)\n",
    "                else:\n",
    "                    result.append(0)\n",
    "        return result\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#------PARAMETROS AJUSTAVEIS-------------\n",
    "# dataset = 'desbalanceado'\n",
    "dataset = 'balanceado'\n",
    "\n",
    "mostra_palavras_mais_frequentes_spams = False\n",
    "mostra_palavras_mais_frequentes_nao_spams  = False\n",
    "\n",
    "use_laplace_smoothing = True\n",
    "laplace_smoothing = 10.0\n",
    "\n",
    "mostra_palavras_frequencia_zero_dentre_spams = False # acionavel quando nao se utiliza Laplace Smoothing\n",
    "mostra_palavras_frequencia_zero_dentre_nao_spams  = False # acionavel quando nao se utiliza Laplace Smoothing\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "\n",
    "if use_laplace_smoothing:\n",
    "    print \"(Utilizando Laplace smoothing %.5f)\" % laplace_smoothing\n",
    "else:\n",
    "    print \"(Nao utilizando Laplace smoothing)\"\n",
    "\n",
    "print \"Carregando dataset %s\" % dataset\n",
    "[X, y, MNB] = pickle.load( open( \"dataset_enron_%s.p\" % dataset, \"rb\" ) )\n",
    "nSpams = sum(y)\n",
    "nTotal = len(y)\n",
    "print \"\\tDataset possui %d spams de um total de %d emails (percentual de spams: %.2f%%)\" % (nSpams, nTotal, 100*nSpams/nTotal)\n",
    "\n",
    "if mostra_palavras_mais_frequentes_spams:\n",
    "    spam_counts = MNB.word_counts['spam']\n",
    "    most_common_spam_words = sorted(spam_counts.items(), key=lambda item: item[1])\n",
    "    print \"Palavras mais comuns em emails do tipo SPAM:\"\n",
    "    for (palavra, contagem) in most_common_spam_words[-51:-70:-1]:\n",
    "        print \"\\t%s: %d vezes\" % (palavra, contagem)\n",
    "\n",
    "if mostra_palavras_mais_frequentes_nao_spams:                \n",
    "    ham_counts = MNB.word_counts['ham']\n",
    "    most_common_ham_words = sorted(ham_counts.items(), key=lambda item: item[1])\n",
    "    print \"Palavras mais comuns em emails do tipo NAO-SPAM:\"\n",
    "    for (palavra, contagem) in most_common_ham_words[-40:-69:-1]:\n",
    "        print \"\\t%s: %d vezes\" % (palavra, contagem)\n",
    "\n",
    "\n",
    "print \"Fazendo predicoes no conjunto de teste...\"\n",
    "pred = MNB.predict(X[:100], use_laplace_smoothing, laplace_smoothing, mostra_palavras_frequencia_zero_dentre_spams, mostra_palavras_frequencia_zero_dentre_nao_spams)\n",
    "#print \"\\tDone predicting\"\n",
    "true = y[:100]\n",
    "\n",
    "emails_corretos = sum(1 for i in range(len(pred)) if pred[i] == true[i])\n",
    "total_emails    = len(pred)\n",
    "acuracia = emails_corretos/float(total_emails)\n",
    "print \"Acuracia: %.4f%%\\t(%d of %d)\" % (100*acuracia, emails_corretos, total_emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}